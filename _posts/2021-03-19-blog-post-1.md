---
title: 'Data Augmentation with CoDA'
date: 2021-03-19
permalink: /data_augmentation_with_coda
tags:
  - NLP
  - Data Augmentation
---

数据增强(Data Augmentation)方法成功地改进了大规模基于神经网络的模型. 然而,现有的大多数研究都是针对计算机视觉(CV)任务.图像数据得以于其构造的特性, 可以使用可以使用剪裁, 翻转, 缩放等操作来扩大数据集. 自然语言的离散性, 让这种**保留标签监督性(label-preserving)**同时有助于模型泛化的简单转换在文本序列上异常困难.  从模型层面来讲，巨无霸式的大型预训练语言模型依靠大量的算力, 在海量的无监督文本下被喂食以先验知识. 但是当将其应用于小样本数据的下游任务时, 往往会因为数据缺失无法表现出其应有的模型能力. 为此Microsoft Dynamics 365 AI和UIUC在这项工作中提出了CoDA方案, 进一步寻找有效的数据增强策略.



Paper Title: *CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding*

Paper Source: ICLR 2021

Paper Link: https://openreview.net/forum?id=Ozk9MrX1hvA



带着下面三个问题, 我们来梳理一下文章的思路

> 1. What are some label-preserving transformations, that can be applied to text, to compose useful augmented samples?
> 2. Are these transformations complementary in nature, and can we find some strategies to consolidate them for producing more diverse augmented examples?
> 3. How can we incorporate the obtained augmented samples into the training process in an effective and principled manner?

## Background

### Data Augmentation

> data augmentation can be regarded as constructing neighborhoods around a training instance that preserve the ground-truth label.

数据增强从概念上来说就是一个对原有数据集合进行数据扩充的方法, 原有训练数据$\mathcal{D}$可以表示为:

$$
\mathcal{D}=\left\{x_{i}, y_{i}\right\}_{i=1 \ldots N}
$$

通过某些label-preserving transformations, 可以是back-translation (Sennrich et al., 2016; Edunov et al., 2018; Xie et al., 2019), mixup (Guo et al., 2019), c-BERT (Wu et al., 2019)转变成新的训练集合:

$$
\mathcal{D}^{\prime}=\left\{x_{i}^{\prime}, {y}_{i}^{\prime}\right\}_{i=1 \ldots N}
$$

基于原有集合$\mathcal{D}$和增强集合$\mathcal{D}^{\prime}$，去学习参数$p_{\theta}(\cdot)$:

$$
\theta^{*}=\underset{\theta}{\arg \min } \sum_{\left(x_{i}, y_{i}\right) \in \mathcal{D}} \mathcal{L}\left(p_{\theta}\left(x_{i}\right), y_{i}\right)+\sum_{\left(x_{i}^{\prime}, y_{i}^{\prime}\right) \in \mathcal{D}^{\prime}} \mathcal{L}\left(p_{\theta}\left(x_{i}^{\prime}\right), y_{i}^{\prime}\right)
$$

**Challenging in NLP**

仿照CV, NLP研究者也提出了一些简单的数据增强方式, e.g. random swap, random insertion, 然而会一定程度上混淆文本的愿义. 下面是来自来自[EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks](https://arxiv.org/abs/1901.11196)的示例:

![image-20210319153919188](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319153919188.png)

下图概括了先期论文工作总结的数据增强方法, 主要是回译(Back-Translation), 以及对抗训练(Adversarial Training)这两种方法以及它们的stacking:

![image-20210319114327077](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319114327077.png)

### Back Translation

Back-Translation一开始是一种写作技巧, 用以增加语言丰富度, 目前被广泛应用于机器翻译领域. BT需要两个seq-to-seq模型的支持, 第一个生成模型得到source->target, 第二个生成模型将target重新译回source. 回译法先利用tgt2src翻译模型将y翻译到$x^{\prime}$, 生成pseudo-parallel data $(x^{\prime},y)$. 再利用生成的伪翻译对$(x^{\prime},y)$更新src2tgt翻译模型. 在机器翻译场景中, BT充分利用了非平行双语数据, 很好地解决了平行语料不足的问题. 

将tgt2src以及src2tgt两个seq-to-seq模型串行, 就可以得到$x \rightarrow y \rightarrow x^{\prime}$:

$$
x_{i}^{\prime}=\text { BackTrans }\left(x_{i}\right)
$$

例如hello(En)->Hallo(Ge)->Hi(En). 这就是将BT作为数据增强技术抽离, 用于文本分类等非机器翻译场景的思路. BT技巧的机器学习解读是:**模型应该对于不同表达形式但同一语义的文本具有不变性.** 因此, 回译这一增强技术的效果主要取决于翻译模型的好坏(encoder + decoder).

在Fig. 1a中, 是一个用英德翻译做数据增强的例子. 对于我们的目标训练参数$p_{\theta}(\cdot)$, 可以通过最小化$
\mathcal{R}_{\mathrm{CS}}\left(p_{\theta}\left(x_i\right), p_{\theta}\left(x_i^{\prime}\right)\right)
$$的方式进行正则化, 保证对于$$(x, x^{\prime})$, $p_{\theta}\left(x_{i}\right)$和$p_{\theta}\left(x_{i}^{\prime}\right)$有一致的概率输出. Loss Fucntion通常采用KL散度.

### Adversarial Training

对抗训练方法被用于文本数据提升模型的鲁棒性. 与数据增强技术相比，对抗训练不需要任何额外的领域知识. 相反, 它依赖于模型本身来给出对抗性样本，即模型最有可能做出不正确预测的样本。与数据增强类似，对抗性训练通常也利用交叉熵和基于一致性的目标进行训练.

下面是两个最常用的对抗训练的loss:


$$
\begin{array}{c}
\mathcal{R}_{\mathrm{AT}}\left(x_{i}, \tilde{x}_{i}, y_{i}\right)=\mathcal{L}\left(p_{\theta}\left(\tilde{x}_{i}\right), y_{i}\right), \text { s.t. }\left\|\tilde{x}_{i}-{x}_{i}\right\| \leq \epsilon \\
\mathcal{R}_{\mathrm{VAT}}\left({x}_{i}, \tilde{x}_{i}\right)=\mathcal{R}_{\mathrm{CS}}\left(p_{\theta}\left(\tilde{x}_{i}\right), p_{\theta}\left({x}_{i}\right)\right), \text { s.t. }\left\|\tilde{x}_{i}-{x}_{i}\right\| \leq \epsilon
\end{array}
$$

通常情况下对抗样本的获取没有closed-form，可以使用基于模型梯度相似的近似方式构造对抗样本:


$$
\hat{x}_{i} \approx {x}_{i}+\epsilon \frac{g}{\|{g}\|_{2}}, \text { where } {g}=\nabla_{x_{i}} \mathcal{L}\left(p_{\theta}\left({x}_{i}\right), y_{i}\right)
$$


## Diversity Promoting Consistency Training

无论是Data Augmentation还是Adversarial Training, 其主要思路都是一致的–找到已有样本的相似样本, 基于样本一致性最小化训练目标. 这时候回顾我们的第二个问题, 即这些不同的数据增强方法是否是等同的或者是互补的? 我们时候是否可以通过混合所有数据增强方法, 来提升模型泛化能力呢？在CV领域，结合不同的数据增强操作被证明可以产生更多样化的增强示例. 然而相同的情况在NLP场景下其具有挑战性，因为一个句子的语义可以通过轻微的干扰而完全产生翻天覆地的变化.

基于五种数据增强方法:

1. Back-translation 
2. C-BERT word replacement
3. mixup
4. cutoff: randomly drops units in a continuous span on the input
5. Adversarial training

本文提出了多种混合数据增强的方法，对于样本数据$x$保持其label $y$一致的情况下, 生成增强数据 $x^{\prime}$, :如下图所示：

![image-20210319132651862](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319132651862.png)

**a) 随机组合(Random combination)**, 在每一个mini-batch中，$x$被一个随机的数据增强方法替换为$x^{\prime}$

**(b) 混合插值(Mixup interpolation)**，在一个mini-batch中的两个样本 $x_i$和$x_j$. 基于两个样本的embedding $e_i$和$e_j$进行线性插值:
$$
{e}_{i}^{\prime}=a {e}_{i}+(1-a) {e}_{j}
$$
其中$a$是插值超参数，符合Beta分布

(c) **顺序叠加(Sequential stacking)**, 样本数据$x$在一系列连续串行叠加的数据增强方法下生成$x^{\prime}$. 由于文本数据本身的离散型, 一些堆叠顺序是天然不可行的. 比如经过对抗训练生成的样本, 不适合用作回翻的输入数据, 合理的堆叠顺序如下图所示:

![image-20210319140848742](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319140848742.png)

即对于训练样本$x_i, y_i$, 上面这种堆叠操作的一致性训练目标可以表示为:

$$
\begin{array}{c}
{x}_{i}^{\prime}=\operatorname{Back} \operatorname{Trans}\left({x}_{i}\right), \hat{x}_{i} \approx \operatorname{argmax}_{\tilde{x}_{i}} \mathcal{R}_{\mathrm{AT}}\left({x}_{i}^{\prime}, \tilde{x}_{i}, y_{i}\right) \\
\mathcal{L}_{\mathrm{consistency}}\left({x}_{i}, \hat{x}_{i}, y_{i}\right)=\mathcal{L}\left(p_{\theta}\left({x}_{i}\right), y_{i}\right)+\alpha \mathcal{L}\left(p_{\theta}\left(\hat{x}_{i}\right), y_{i}\right)+\beta \mathcal{R}_{\mathrm{CS}}\left(p_{\theta}\left({x}_{i}\right), p_{\theta}\left(\hat{x}_{i}\right)\right)
\end{array}
$$

即先用$x_i$做回译得到$x_i^{\prime}$，在新的训练集合中找到模型最难分辨的对抗样本$\hat{x}$.   $\hat{x}$是通过两种不同的label-preserving transformations获得的，因此在数据分布上偏离$x_i$更远，应该比$x_i^{\prime}$更多样化. 中第一项为模型训练本身的交叉熵函数，第二项表示对抗性损失，第三项是一致性损失项, 文中采用Jensen-Shannon divergence:

$$
\left.\mathcal{R}_{\mathrm{CS}}\left(p_{\theta}\left({x}_{i}\right), p_{\theta}\left(\hat{x}_{i}\right)\right)=\frac{1}{2}\left(\operatorname{KL}\left(p_{\theta}\left({x}_{i}\right) \| M\right)+\operatorname{KL}\left(p_{\theta}\left(\hat{x}_{i}\right)\right) \| M\right)\right)
$$

其中$M=\frac{\left(p_{\theta}\left(x_i\right)+p_{\theta}\left(\hat{x}_i\right)\right)}{2}$ 

##  Contrastive Regularization

上述Loss的学习目标都是保持$x_i$和$x_i^{\prime}$预测结果的一致性. 然而文章提出, 除了关心$(x_i, x_i^{\prime})$, $(x_i^{\prime}, x_j), i\neq j$的关系也值得我们考虑. 即在数据表征层面, 增强数据$ x_i^{\prime}$应该直观地接近于其原始数据$x_i$, 同时相对远离其他数据点$x_j$. 

这个直观的想法衍生出一个额外的对比学习(Contrastive  learning)目标, 如下图所示:

![image-20210319132736104](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319132736104.png)

对比学习先期工作中发现, 采用large batch size能够较好地提升训练有效性, 为此CoDA引入了Memory bank来存储历史embeding, 从而使得**大量负样本数据**在训练中的引入成为可能. 同时, 为了避免encoder在训练过程中变化太快(可能导致embeding不一致)，还在算法中加入了基于动量的momentum encoder module, 在每一步参数更新逻辑调整为

$$
\bar{\theta} \leftarrow \gamma \bar{\theta}+(1-\gamma) \theta
$$

其中$\theta$, $\bar{\theta}$分别为query encoder和key encoder的参数. 对于训练样本$x_i$以及它的增强样本$x_i^{\prime}$可以得到query和key的表征:

$$
{q}{i}=f{\theta}\left({x}{i}\right), \quad {q}{i} ({\prime}=f_{\theta}\left({x}_{i}){\prime}\right), \quad {k}{i}=f{\bar{\theta}}\left({x}_{i}\right)
$$

它们的对抗学习目标可以写作:

$$
\begin{aligned}
\mathcal{R}_{\text {contrast }}\left({x}_{i}, {x}_{i}^{\prime}, \mathcal{M}\right) &=\mathcal{R}_{\mathrm{CT}}\left({q}_{i}, {k}_{i}, \mathcal{M}\right)+\mathcal{R}_{\mathrm{CT}}\left({q}_{i}^{\prime}, {k}_{i}, \mathcal{M}\right) \\
\mathcal{R}_{\mathrm{CT}}\left({q}_{i}, {k}_{i}, \mathcal{M}\right) &=-\log \frac{\exp \left(\operatorname{sim}\left({q}_{i}, {k}_{i}\right) / \tau\right)}{\sum_{k_{j} \in \mathcal{M} \cup\left\{k_{i}\right\}} \exp \left(\operatorname{sim}\left({q}_{i}, {k}_{j}\right) / \tau\right)}
\end{aligned}
$$

其中$\gamma$是temperature, $\mathcal{M}$是memory bank, $\operatorname{sim}(\cdot)$选取Cosine similarity.  第一项$\mathcal{R}_{\mathrm{CT}}\left(q_i, k_i, \mathcal{M}\right)$基于原始样本计算而来, 表示self-contrastive loss; 第二项 $\mathcal{R}_{\mathrm{CT}}\left(q_i^{\prime}, k_i, \mathcal{M}\right)$由增强样本$ x_i^{\prime}$得到, 表示augment-contrastive loss. 其表达的想法显而易见–**原始样本和增强样本对相对于memory bank中的负样本，在学习表征特征时应保持更近的距离.** 这个loss为我们提供了global information, 使得整个训练得到了宏观正则化.

将local consistency loss 与 global contrastive loss整合后, 可以得到CoDA框架的最终目标函数:

$$
\theta^{*}=\operatorname{argmin}_{\theta} \sum_{\left({x}_{i}, y_{i}\right) \in \mathcal{D}} \mathcal{L}_{\text {consistency }}\left({x}_{i}, {x}_{i}^{\prime}, y_{i}\right)+\lambda \mathcal{R}_{\text {contrast }}\left({x}_{i}, {x}_{i}^{\prime}, \mathcal{M}\right)
$$

## Experiments

###  Combining Label-Preserving Transformations 

单一数据增强方法

* 所有数据增强方法都在RoBERTa-base模型基础上取得了进步，证明了利用Label-Preserving Transformations 在NLU场景下的有效性
* mixup和c-BERT相比, back-translation, cutoff和adversarial training的实证结果更强.

混合数据增强方法

* back-translation + adversarial training的顺序堆叠方式最有效(应用于以下所有实验)


![image-20210319132836410](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319132836410.png)

### Contrastive Regularization Design

选取了不同的temperature以及memory bank size进行实验

![image-20210319151710976](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319151710976.png)

###  GLUE Benchmark Evaluation

![image-20210319150803993](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319150803993.png)

* 在BLUE数据集下, CoDa在几乎所有子任务下都表现出了比其他数据增强方法都优秀的结果.

* 相比Roberta-large model, 表现出了平均2.2%的提升. 

### 额外实验分析

小样本数据实验

![image-20210319152208951](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319152208951.png)

对抗目标有效性

为了研究所提出的对比正则化目标的一般适用性，进一步将其应用于不同的数据增强方法. 使用RoBERTa-base模型和QNLI数据集进行这组实验. 

![image-20210319152227906](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319152227906.png)

可以观察到，在多个数据增强方法下, 对比学习目标都能有效模型的性能. 这进一步验证了对抗训练引入的全局信息有利于更有效地利用增强样本.