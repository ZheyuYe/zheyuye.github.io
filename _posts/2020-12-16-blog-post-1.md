---
title: 'Experience Grounds Language'
date: 2021-01-17
permalink: /experience_grounds_language/
tags:
  - EMNLP2020
  - NLP
---

这是一篇来自EMNLP 2020的文章, 多个高校、机构的大佬们在此为NLP领域构想了一个蓝图. 这个蓝图将我们的思绪从简单的构造模型解答谜题转移到深层次的语言学习本质上. 语言是一种沟通工具, 起到了**描绘物理世界**以及**促进社会交互**的作用, 而语言理解研究停滞不前的也可以归因于未能将语言和上述作用紧密联系起来. 而现有的NLP技术, 正如其名地, 把语言当成了处理工具, 尽管在文本任务上的应用取得了巨大的成功, 但语言交流往往是需要依赖于shared experience of the world, 才不致于呆板沉闷且失去生机.

Paper Title: *Experience Grounds Language*

Paper Source: EMNLP 2020

Paper Link: [https:/c/arxiv.org/abs/2004.10151](https://arxiv.org/abs/2004.10151)

## 成长设定

近些年来随着语言模型技术的成熟, 预训练模型的不断拓展, 在大量语料和模型的帮助下, NLP技术在不同领域的多项任务的benchmarks上已经超过了人类水平, 包括文本分类任务([GLUE](https://gluebenchmark.com/)), 抽取式问答任务([SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)).  然而有一个问题始终摆在我们面前:

> Where is NLP going?

似乎竭尽所有AI从业者之力所构造的模型都只是在尝试解答限定范围的特点任务, 模型能力的可解释性一直是困扰学者的一大难题. 大量人工标注数据堆砌而成的强大语言模型, 似乎也只是照本宣科, 能做到举一反三却难以触类旁通更不用说融会贯通了.

>Meaning does not arise from the statistical distribution of words, but from their use by people to communicate.

诚然, 单靠文字是学不会语言的, 而如何为NLP注入理解则是本文重点想要讨论的问题.**extra linguistic events**(语言之外的事件)和**social context**(社会环境)在被认为是指导未来研究方向的两个重要组成部分.

**World Scope (WS)**这个概念被引入作为NLP领域的进展阶段. 可具体分为以下五个阶段:

1. 语料 (Corpus) -- 过去式
2. 互联网 (Internet) -- 现有阶段
3. Perception (感知) -- 多模态NLP
4. Embodiment (具身)
5. Social (社交)

## WS1-语料与表征

从零出发, 文本永远是模型成长进步的第一份养分. 从文本当中找到文字的**意义(meaning)**成为了最主要的想法. 最初的研究方向来自于一个直观的想法--结构化语言, [Penn Treebank](https://catalog.ldc.upenn.edu/LDC99T42)正是在那个阶段产生的经典数据集,  产生了诸如恢复语法树之类的, 围绕语言语法结构的经典NLP任务类型. 

找到一个合适的**文本表示(Word representations)**代表其意义变成学界的研究重点, 且远在深度学习火热之前就如火如荼了. 哲学家和语言学家阐述到, "意义是灵活变化而结构化的";  Elman和Bengio也早在上世纪末-本世纪初指出**向量表示(vector representations)** 可以捕获到文本中的语法和语义信息; 尽管*上下文环境蕴含了意义*这一点已经得到公认, 但是如何有效得获取上下文信息还是引得几代研究学者前仆后继, 期间也有一些重要工作产生:

1. 互信息引导的层次聚类 
2. Baum–Welch + 无监督隐马尔可夫链生成词类别
3. 隐狄利克雷分布模型框架LDA主题生成模型
4. LSI/A使用奇异值分解实现共生矩阵到低维词向量的映射

到近年来语言表示中的里程碑工作静态词向量([Word2Vec](https://arxiv.org/abs/1310.4546)和[Glove](https://www.aclweb.org/anthology/D14-1162/)), 预训练模型([ELMo](https://arxiv.org/abs/1802.05365), [GPT](https://openai.com/blog/better-language-models/), [BERT](https://arxiv.org/abs/1810.04805), etc). 前者由词义的分布式假设)出发得到一个向量字典, 每一个单词被映射到一个唯一的稠密向量;  后者结合上下文构建深层模型动态生成词向量, 很好地解决了一词多义的问题(polysemy).

[**符号主义(symbolism)**](https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence)和[**连接主义(connectionism)**](https://en.wikipedia.org/wiki/Connectionism)作为人工智能不同学派, 其二者的争论从未停止.  在NLP世界中可被具体化为

1. 对符号建模(modeling symbols): 对于每个元素, 生成一个由意义的局部表示
2. 生成分布式表征(distributed representations):  利用深度神经网络生成没有具体释义的向量表示

## WS2-丰富的文本

纷纷扰扰的繁华世界簇拥着越来越多的文本资源, 也不断滋养着NLP模型进化成长. 在大规模数据的哺育和大规模训练资源的支持下, 诸如[BERT](https://arxiv.org/abs/1810.04805)和[GPT3](https://arxiv.org/abs/2005.14165)都可以在不需要我们额外帮助的情况下, 无监督地将大量知识迁移到不同领域背景下. 

训练所需要的语料规模以及参数规模也在这个阶段大幅上升, 2013年时Word2Vec的训练成本是1.6 billion tokens, 次年的Glove在[Common Crawl](https://commoncrawl.org/)的帮助下将这个数字提升到了 840 billion. 2018年基于双向LSTM实现的语言模型ELMo的参数数量级在10^8, 而2020年的巨无霸GPT3则是调用了大约10^11的参数. 

哪怕取得了令人惊艳的模型性能, 屠榜各大任务, 超过人类表现, 这项NLP领域的现代主力的主要思想依然没有变化, 即对丰富文本中的词汇共现规律建模, 且正在表现出明显的**边际效益递减(diminishing returns)**: 在[LAMBADA](https://arxiv.org/abs/1606.06031)任务下, [GPT2](https://openai.com/blog/better-language-models/)(1.5B), [Megatron-LM](https://arxiv.org/abs/1909.08053)(8.3B), [TuringNLG](https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/)(17B)这几个模型并没有随着参数数量的增长而在准确率上呈现出明显提升, 直到GPT3(175B)才将这一结果提升了8个百分点. 学界也渐渐被这种思想腐蚀, 追求更大更强, SOTA->屠榜->发Paper似乎成为了主流, 而一个预训练模型的训练计算成本是高昂的, 算力开销上的损耗与边际效益递减呈现出的冲突不禁让我们思考.

句子和文档固然能为学习meaning提供足够的信号, 特别单词与单词之间的语义关系以及句子与句子间的推理关系. 然而还有一个悬而未决的问题是, 消耗大量算力成本的预训练模型是否能有效获取**语境信息**. 有明确答案的是, 现有语言模型对于一些棘手的NLP任务仍然束手无策, 例如下面这个[hard coreference problem](https://www.aclweb.org/anthology/N15-1082/)

> I parked my car in the compact parking space because it looked (big/small) enough.

上述问题的解答需要模型对于世界的认知有commonsense, 或者说知道停车是怎么一回事, 简单地将"small"映射到前文的"compact"则会得到错误的答案. 

海量的, 非结构化的, 多领域的, 无标签的文本让语言模型得到了很好的强化, 但是观察这个世界学习meaning的过程中也不应该只有语言参与到其中来, 这也促使我们照着多模态感知的方向前进. 

## WS3-多维度感知

感知(perception)构成了我们许多语义公理的基础, 感知世界理解世界, 丰富阅历以及见识, 才能更好的掌握语言. 一个不太恰当的例子是盲人会说会听, 会发声会写字, 但是没法真正理解什么是"热情的红色", "压抑的黑色", "忧郁的蓝色".  儿童牙牙学语的过程中, 更是需要多种感官的高度配合, 去听去感受.  而隐喻(metaphors)更是集人类语言之精华, 是幽默, 智慧的体现, 作为一种人类思维的重要手段直接参与世界认知的学习过程当中去. (George Lakoff. 1980. *Metaphors We Live By*). (O.S. :买了这本书当枕边读物, 虽然只看了两页还没看完, 看到被顶会论文cite还是有些激动)

利用多模态对各种不同的感知建模, 结合自然语言处理(NLP)与计算机视觉(CV)等其他涉及的领域向多模态发展需要跨领域的共同努力. 计算机视觉作为视觉感知信号的应用, 已经深入到复杂的视觉、物理和社会现象中，同时提供了大量可复用的模型组件, 也使得其与自然语言的交互成为可能. 图像标注(Image Caption), 视觉问答(Visual Question Answering), 自然语言与视觉推理(Natural Language and Visual Reasoning), 视觉常识(Visual Commonsense), 多语言视频翻译(Multilingual Captioning/Translation via Video)等交互任务的数据集不断完善丰富, 也使得训练大型多模态Transformers不再是天方夜谭. Open AI也在最近放出大招, [DALL·E](https://openai.com/blog/dall-e/)使用了GPT-3的120亿参数版本, 可以通过文本直接生成图像.

与之对应的, NLP在多模态应用上同样功不可没. 赫赫有名的图像分类数据集[ImageNet](http://www.image-net.org/)使用了[WordNet](https://wordnet.princeton.edu/)分类词库中的类别分层关系, 这就使得在探究类别概念的meaning过程中引入图像分类预训练的层次语义信息. e.g. "人" 是许多职业以及爱好的上位词(hypernyms), 包括消防员, 运动员, 医生等等. 将穿着, 妆发, 周围场景等低级别图像特征编码后, 上述子类词的差异化会得到的更好体现, 而这些差异化特征是单纯文本信息无法提供的.  这也让零次学习(Zero-Shot Learning)成为了可能, 结合多模态的特征学习获得的额外感知信息, 计算机能够做到基于已有信息展开简单推理, 从而辨别新事物学习新特征.

## WS4-具身与实践

世界纷繁难免“乱花渐欲迷人眼”, 在去听去看去感受之余, 更应该把自己置身其中, 去行动去犯错去验证“听过很多道理，依然过不好这一生”. 在第四个层级的World Scope中, 模型被要求在实践中理解meaning, 践行每一个基础的名词概念, 探究文字与互动式多模态感知的紧密联系. 从而主动地在环境当中真正理解语言.

让我们来深入思考下面这个最无关痛痒的问题:

> 橘子更像是棒球还是香蕉？

结合前面三个层次的World Scope, 我们不难发现WS1会认为三者都是普通名词, 橘子和香蕉可能共现频率更高而被认为更相近; 基于上下文语义的WS2可能捕捉到橘子和棒球都是球状的，但是对于它们的变形强度、表面纹理或者相对大小一无所知; 在获取了大量感知信息后, WS3系统会了解到橘子、棒球和香蕉的外观以及表面纹理从而选择棒球，但是光从图片可能无法分辨橘子和棒球二者的软硬程度; WS4会基于互动式行为, 理解这个问题的细微差别: 橘子和棒球有相似的质地和重量，而橘子和香蕉都被果皮包覆, 有着相同的软硬程度和用途。

**pre-linguistic representations**



让我们和NLP一起去践行“知行合一”吧~



## 社交与社会



很喜欢知乎上的[这个回答](https://www.zhihu.com/question/438449811/answer/1670951547)

>  等什么时候AI可以听懂相声和脱口秀再说吧.



To be continued.