---
title: 'DeBERTa: Decoding-enhanced BERT with Disentangled Attention'
date: 2021-03-28
permalink: /deberta
tags:
  - NLP
  - Pre-trained Model

---





Paper Title: *DeBERTa: Decoding-enhanced BERT with Disentangled Attention*

Paper Source: ICLR 2021

Paper Link: [https://openreview.net/forum?id=XPZIaotutsD](https://openreview.net/forum?id=XPZIaotutsD)

Official Blog: https://www.microsoft.com/en-us/research/blog/microsoft-deberta-surpasses-human-performance-on-the-superglue-benchmark/

Code Link: https://github.com/microsoft/DeBERTa